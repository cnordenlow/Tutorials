[
["index.html", "Templates Intro", " Templates christoffer.nordenlow@riksbank.se 2020-05-26 Intro This repository includes useful templates, formulas and code for R and VBA, also in combination with Bloomberg formulas and Fixed Income analysis. "],
["r.html", "1 R 1.1 Create template tables 1.2 Import &amp; Export 1.3 Tidy &amp; Transform 1.4 Working with strings and characters 1.5 Visualize 1.6 Misc 1.7 R Markdown 1.8 Web Scraping", " 1 R 1.1 Create template tables 1.1.1 Template tables Create table with random dates between two dates. Use max date and create a table with dates until this date. #https://www.cyclismo.org/tutorial/R/basicOps.html#basic-operations library(dplyr) df &lt;- tibble( date = sample(seq(as.Date(&#39;2020/06/01&#39;), as.Date(&#39;2025/01/01&#39;), by=&quot;day&quot;), 20) ) df2 &lt;-tibble( date = seq.Date(Sys.Date(), max(as.Date(df$date)), by = &quot;day&quot;) ) Create new column with random number library(tidyverse) df &lt;- data.frame(Amount = 1:10) df %&gt;% rowwise %&gt;% mutate(newColumn = sample(1:5, 1)) #It´s often neccessary to ungroup rowwise. df &lt;- as.data.frame(df) Create table with a combination of fixed and random numbers library(tidyverse) df &lt;- tibble( value = seq(10,90,1), rand = seq(10,90,1) +runif(81, min=-10, max=15) ) **Create a list and bind together, only 1 column* libary(dplyr) lst &lt;- list(cars, cars) lst &lt;- bind_rows(lst) lst %&gt;% select(2) #Bind together list, include the index number / name. Use data.table library(data.table) lst &lt;- list(cars, cars) lst &lt;- rbindlist(lst, idcol = TRUE) 1.2 Import &amp; Export 1.2.1 Import Import fast using httpcashe Improving efficiency in importing get_data &lt;- function(url) { httpcache::GET(url) %&gt;% httr::content() } url_jobless_claims=&quot;https://oui.doleta.gov/unemploy/csv/ar539.csv&quot; data_jobless_claims &lt;- get_data(url_jobless_claims) Import all files in a folder Import all files in a folder. In the example below files are named “2020-05-05 Saldo”. Import and create a table where the date of the filename is used in a column. Change name for column 1 and 2. Map has similiar functionality to lapply. When you add _dfr it will generate data.frames and that these is merged. parse_date &lt;- function(x) as.Date(gsub( &quot;.*(\\\\d{4}-\\\\d{2}-\\\\d{2}).*&quot;, &quot;\\\\1&quot;, x)) dir_loc &lt;- &#39;X:\\\\Likviditet\\\\RIX-filer\\\\Saldo&#39; rix_saldo &lt;- dir(dir_loc, full.names = T) %&gt;% map_dfr(~{ read.csv2(.x, skip = 1, header = F) %&gt;% mutate(date = as.Date(parse_date(basename(.x)))) }) colnames(rix_saldo)[colnames(rix_saldo) == &#39;V1&#39;] &lt;- &#39;Participant&#39; colnames(rix_saldo)[colnames(rix_saldo) == &#39;V2&#39;] &lt;- &#39;Saldo&#39; Import excel from web Import excel from web by downloading it temp library(readxl) url_data_gdp &lt;- (&quot;https://www.bea.gov/system/files/2020-04/qgdpstate0420.xlsx&quot;) download.file(url=url_data_gdp, destfile=&quot;localcopy.xlsx&quot;, mode=&quot;wb&quot;) #Table 1: Percent Change in Real Gross Domestic Product (GDP) by State and state table1 &lt;- read_excel(&#39;localcopy.xlsx&#39;, sheet = 1, skip =4, col_names = FALSE) 1.2.2 Export Export to txt file write.table(table_for_report, &quot;...\\\\Operations\\\\LikvProg\\\\likvprog_history.txt&quot;, sep=&quot;\\t&quot;) Export to csv file #Using both write.csv2 or write.table library(data.table) #Write csv2. No row.names, na = &quot;&quot; and quote (&quot;&quot;) mark as false write.csv2(total_purchases_commercial_papers, &quot;.....R_tables\\\\Output_data\\\\webpage_purchases\\\\Total_purchases_commercial_papers.csv&quot;,row.names=FALSE,na = &quot;&quot;, quote = FALSE) #Write.table. No row.names, na = &quot;&quot; and quote (&quot;&quot;) mark as false write.table(total_purchases_commercial_papers,file=&quot;...\\\\Total_purchases_commercial_papers3.csv&quot;,row.names=FALSE,sep=&quot;;&quot;,dec = &quot; &quot;,quote = FALSE) Get table to paste into excel write.excel &lt;- function(x,row.names=FALSE,col.names=TRUE,...) { write.table(df,&quot;clipboard&quot;,sep=&quot;\\t&quot;,row.names=row.names,col.names=col.names,...) } write.excel(my.df) 1.3 Tidy &amp; Transform 1.3.1 Cleaning Cleaning some data Gather, Spread, Separate, Unite library(tidyr) #Create a messy dataset messy &lt;- data.frame( country = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;), q1_2017 = c(0.03, 0.05, 0.01), q2_2017 = c(0.05, 0.07, 0.02), q3_2017 = c(0.04, 0.05, 0.01), q4_2017 = c(0.03, 0.02, 0.04)) messy #Reshape the data. in this function we create two new variables instead of the one in the original dataset. tidier &lt;- messy%&gt;% gather(quarter, growth, q1_2017:q4_2017) tidier #Spread #the spread function does the opposite of gather. #Reshape the tidier dataset back to messy. messy_1 &lt;- tidier %&gt;% spread(quarter, growth) messy_1 #Separate #Separate splits a column into two according to a separator. This function is helpful in some situations where the variable is a date, i.e. separate year and month. separate_tidier &lt;- tidier %&gt;% separate(quarter, c(&quot;Qrt&quot;, &quot;year&quot;), sep =&quot;_&quot;) head(separate_tidier) #Unite #Unite concatenates two columns into one. unit_tidier &lt;- separate_tidier%&gt;% unite(Quarter, Qrt, year, sep = &quot;_&quot;) head(unit_tidier) 1.3.2 Expand Expand table One example with expanding to all alternatives. Another to fill in gaps. library(tidyverse) library(dplyr) ##Expand all alternatives a &lt;- c(1:10) b &lt;- c(1:10) c &lt;- c(1:10) df &lt;- tibble(a,b,c) all_combinations &lt;- expand(df, a,b,c) #Expand by missing Date df &lt;- tibble( year = c(2010, 2010, 2010, 2010, 2012, 2012, 2012), qtr = c( 1, 2, 3, 4, 1, 2, 3), return = rnorm(7) ) df %&gt;% expand(year, qtr) df %&gt;% expand(year = 2010:2012, qtr) df %&gt;% complete(year = full_seq(year, 1), qtr) 1.3.3 Join and Merge Join tables Different ways to join tables. library(dplyr) df_primary &lt;- tribble( ~ID,~y, &quot;A&quot;, 5, &quot;B&quot;, 5, &quot;C&quot;, 8, &quot;D&quot;, 0, &quot;E&quot;, 9) df_secondary &lt;- tribble( ~ID,~y, &quot;A&quot;, 30, &quot;B&quot;, 21, &quot;C&quot;, 22, &quot;D&quot;, 25, &quot;F&quot;, 29) #Most common way to merge two datasets is to uset the left_join() function. left_join_ &lt;- left_join(df_primary, df_secondary, by =&#39;ID&#39;) #The right_join works like the left one. right_join_ &lt;- right_join(df_primary, df_secondary, by = &#39;ID&#39;) #When we are sure that two datasets won´t match, we can consider to return only rows existing in both datasets. #This is legit when we need a clean dataset or when we dont want to impute missing values with the mean or median. inner_join_ &lt;- inner_join(df_primary, df_secondary, by =&#39;ID&#39;) # Full_join keeps all observations and replace missing values with NA. full_join_ &lt;- full_join(df_primary, df_secondary, by = &#39;ID&#39;) Join tables on multiple conditions Join Tables on multiple conditions library(dplyr) df_primary &lt;- tribble( ~ID, ~year, ~items, &quot;A&quot;, 2015,3, &quot;A&quot;, 2016,7, &quot;A&quot;, 2017,6, &quot;B&quot;, 2015,4, &quot;B&quot;, 2016,8, &quot;B&quot;, 2017,7, &quot;C&quot;, 2015,4, &quot;C&quot;, 2016,6, &quot;C&quot;, 2017,6) df_secondary &lt;- tribble( ~ID, ~year, ~prices, &quot;A&quot;, 2015,9, &quot;A&quot;, 2016,8, &quot;A&quot;, 2017,12, &quot;B&quot;, 2015,13, &quot;B&quot;, 2016,14, &quot;B&quot;, 2017,6, &quot;C&quot;, 2015,15, &quot;C&quot;, 2016,15, &quot;C&quot;, 2017,13) left_join(df_primary, df_secondary, by = c(&#39;ID&#39;, &#39;year&#39;)) Merge Data Frames Merge Data Frames in R: Full and partial match producers &lt;- data.frame( surname = c(&quot;Spielberg&quot;,&quot;Scorsese&quot;,&quot;Hitchcock&quot;,&quot;Tarantino&quot;,&quot;Polanski&quot;), nationality = c(&quot;US&quot;,&quot;US&quot;,&quot;UK&quot;,&quot;US&quot;,&quot;Poland&quot;), stringsAsFactors=FALSE) # Create destination dataframe movies &lt;- data.frame( surname = c(&quot;Spielberg&quot;, &quot;Scorsese&quot;, &quot;Hitchcock&quot;, &quot;Hitchcock&quot;, &quot;Spielberg&quot;, &quot;Tarantino&quot;, &quot;Polanski&quot;), title = c(&quot;Super 8&quot;, &quot;Taxi Driver&quot;, &quot;Psycho&quot;, &quot;North by Northwest&quot;, &quot;Catch Me If You Can&quot;, &quot;Reservoir Dogs&quot;,&quot;Chinatown&quot;), stringsAsFactors=FALSE) m1 &lt;- merge(producers, movies, by.x = &quot;surname&quot;) m1 # Change name of ` movies ` dataframe colnames(movies)[colnames(movies) == &#39;surname&#39;] &lt;- &#39;name&#39; # Merge with different key value m2 &lt;- merge(producers, movies, by.x = &quot;surname&quot;, by.y = &quot;name&quot;) ##Partial match # Create a new producer add_producer &lt;- c(&#39;Lucas&#39;, &#39;US&#39;) # Append it to the ` producer` dataframe producers &lt;- rbind(producers, add_producer) # Use a partial merge m3 &lt;-merge(producers, movies, by.x = &quot;surname&quot;, by.y = &quot;name&quot;, all.x = TRUE) m3 1.3.4 Transforming data with Apply etc apply(), lapply(), sapply(), tapply() apply() library(dplyr) m1 &lt;- matrix(c&lt;-(1:10), nrow=5,ncol=6) m1 #Sums columns a_m1 &lt;- apply(m1,2,sum) a_m1 #Sums rows a_m1 &lt;- apply(m1,1,sum) a_m1 lapply() library(dplyr) movies &lt;- c(&quot;spyderman&quot;, &quot;batman&quot;, &quot;vertigo&quot;, &quot;chinatown&quot;) movies_lower &lt;- lapply(movies, tolower) str(movies_lower) #if we like to convert the list into a vector we can use unlist() movies_lower &lt;- unlist(lapply(movies, tolower)) str(movies_lower) sapply() #sapply() function does the same jobs as lapply() function but returns a vectorÄ library(dplyr) dt &lt;- cars lmn_cars &lt;- lapply(dt, min) smn_cars &lt;- sapply(dt,min) lmn_cars smn_cars lmxcars &lt;- lapply(dt,max) smxcars &lt;- sapply(dt,max) lmxcars smxcars #lets create a function names avg to compute the average of the minimun and maximun of the vector. avg &lt;- function(x){ (min(x) + max(x))/2 } fcars &lt;- sapply(dt, avg) fcars #sapply() function is more efficient than lapply() in the output returned because sapply() store values directly into a vector. #it is possible to use lapply or sapply interchangeable to slice a data frame. #lets compute a function that takes a vector of numerical values and returns a vector that only contains the values that are strictly above the average. below_ave &lt;- function(x){ ave &lt;- mean(x) return(x[x&gt;ave]) } dt_s &lt;- sapply(dt, below_ave) dt_l &lt;- lapply(dt, below_ave) identical(dt_s, dt_l) tapply() #The function tapply() computes a measure (mean, median, min, max) or a function for each factor variable in a vector library(dplyr) data(iris) tapply(iris$Sepal.Width, iris$Species, median) 1.3.5 Tally-function Tally() Tally is a useful wrapper for summarise with grouping conditions. In the example below we have a data set with countries. For US, there are no aggregate number, so we need to summarize each state. library(tidyr) library(dplyr) df &lt;- tibble::tribble( ~country, ~state, ~t1, ~t2, &quot;SE&quot;, NA, 1,2, &quot;US&quot;, &quot;A&quot;, 10,20, &quot;US&quot;, &quot;B&quot;, 11,21, ) df%&gt;% tidyr::gather(date, value, -country, -state)%&gt;% group_by(country, date) %&gt;% tally(value) 1.3.6 Useful functions / expressions Sub / Gsub Replace the first occurence of a pattern with a sub or replace all occurrences with gsub. Gsub() replaces all matches of a string. x &lt;- &quot;Old City&quot; gsub(&quot;Old&quot;, &quot;New&quot;, x) #case insensitive gsub(&quot;old&quot;, &quot;New&quot;, x, ignore.case=T) #Vector replacement y &lt;- c(&quot;Stockholm City&quot;, &quot;Uppsala City&quot;, &quot;Malmö&quot;) gsub(&quot; City&quot;,&quot;&quot;,y) rnorm Generate number from a normal distribution. rnorm(4) #&gt; [1] -2.3308287 -0.9073857 -0.7638332 -0.2193786 # Use a different mean and standard deviation rnorm(4, mean=50, sd=10) #&gt; [1] 59.20927 40.12440 44.58840 41.97056 # To check that the distribution looks right, make a histogram of the numbers x &lt;- rnorm(400, mean=50, sd=10) hist(x) slice Example: way to take out a single row. library(dplyr) mtcars select_row = 1 df &lt;- arrange(mtcars, mpg) df2 &lt;- df %&gt;% slice(which(row_number() == select_row)) unique Example: get all unique values in a column library(dplyr) library(data.table) df &lt;- mtcars unique(df$cyl, incomparables = FALSE) 1.4 Working with strings and characters Remove last n characters #Remove last n characters in a string df &lt;- tibble( program = c(rep(&quot;okv 20200528&quot;,10), rep(&quot;ftg 20200525&quot;,10)) ) df$program &lt;- substr(df$program,1,nchar(df$program)-9) 1.5 Visualize 1.5.1 Ggplots geom_line with geom_ribbon geom_line with geom_ribbon for pos / neg numbers library(ggplot2) df &lt;- tibble( value = seq(1,50,1), rand = seq(1,50,1) +runif(50, min=-10, max=15) )%&gt;% mutate(diff = rand - value) exposure_graph &lt;- ggplot(df, aes(x=value,y=rand)) + geom_ribbon(aes(ymin=pmin(df$diff,0), ymax=0), fill=&quot;red&quot;, col=&quot;black&quot;, alpha=0.5) + geom_ribbon(aes(ymin=0, ymax=pmax(df$diff,0)), fill=&quot;blue&quot;, col=&quot;black&quot;, alpha=0.5) + geom_line(aes(y=0)) 1.5.2 Different tables Create table with kableExtra Create table with different colors for pos / neg numbers library(tidyverse) library(kableExtra) df &lt;- tibble( type = c(&quot;gov_bond&quot;, &quot;ssa&quot;, &quot;ssa&quot;, &quot;gov_bond&quot;,&quot;ssa&quot;, &quot;ssa&quot;, &quot;gov_bond&quot;, &quot;gov_bond&quot;, &quot;gov_bond&quot;, &quot;ssa&quot;), maturity_bucket = as.integer(runif(10, min =1, max=6)), diff_bm = runif(10, min = -10, max = 10) ) sum_type &lt;- df %&gt;% group_by(type, maturity_bucket)%&gt;% summarise( diff_exposure = round(sum(diff_bm),1) ) ## Create table with green for positive, red for negative sum_table &lt;- sum_type%&gt;% mutate( diff_exposure = ifelse(diff_exposure &lt; 0, cell_spec(diff_exposure, &quot;html&quot;, color = &quot;red&quot;, bold = T), cell_spec(diff_exposure, &quot;html&quot;, color = &quot;green&quot;, italic = T)))%&gt;% kable(&quot;html&quot;, escape = F, format.args=list(big.mark=&quot; &quot;, scientific=F)) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;), full_width = F, position= &quot;right&quot;, fixed_thead = T) sum_table 1.6 Misc 1.6.1 Moving average Create a moving average Example of creating a moving average for dates. library(tidyverse) library(dplyr) library(lubridate) df &lt;- tibble( Date = seq.Date(Sys.Date()-19, Sys.Date(), by=&quot;day&quot;), indicator = c(rep(1,10),rep(2,10)), value = rnorm(20) ) df &lt;- arrange(df, Date) df %&gt;% group_by(indicator) %&gt;% mutate(MA_3m = slide_index_dbl(value, Date, mean, .before=lubridate::days(2), .after=0,.complete=T)) #Use before or after = Inf if you like to get the calculation based on all values before or after. 1.6.2 Date Formating Different ways to format dates Dates as.Date(&quot;2/15/1986&quot;, format = &quot;%m/%d/%Y&quot;) Formating date with use of gsub to adjust the the string. library(tidyverse) date_to_format = &quot;2016-10-17 UTC&quot; as.Date(gsub(&quot;\\\\D&quot;, &quot;&quot;, date_to_format), format = &quot;%Y%m%d&quot;) #or changing who table df &lt;- tibble( date_to_format = &quot;2016-10-17 UTC&quot; ) df &lt;- df %&gt;% mutate(date_to_format = as.Date(gsub(&quot;\\\\D&quot;, &quot;&quot;, date_to_format), format = &quot;%Y%m%d&quot;)) 1.6.3 Loops 1.6.3.1 For loop example Creates a non-linear function by using the polynomial of x between 1 and 4 and we store it in a list # # Create an empty list list &lt;- c() # Create a for statement to populate the list for (i in seq(1, 4, by=1)) { list[[i]] &lt;- i*i } print(list) For loop over a matrix A matrix has 2-dimension, rows and columns. To iterate over a matrix, we have to define two for loop, namely one for the rows and another for the column. # Create a matrix mat &lt;- matrix(data = seq(10, 20, by=1), nrow = 6, ncol =2) # Create the loop with r and c to iterate over the matrix for (r in 1:nrow(mat)) for (c in 1:ncol(mat)) print(paste(&quot;Row&quot;, r, &quot;and column&quot;,c, &quot;have values of&quot;, mat[r,c])) 1.6.3.2 For loop example Creates a non-linear function by using the polynomial of x between 1 and 4 and we store it in a list # # Create an empty list list &lt;- c() # Create a for statement to populate the list for (i in seq(1, 4, by=1)) { list[[i]] &lt;- i*i } print(list) Function for Right and Left Functions for Right and Left. library(dplyr) right = function(text, num_char) { substr(text, nchar(text) - (num_char-1), nchar(text)) } left = function(text, num_char) { substr(text, 1, num_char) } df &lt;- tibble( Date = seq.Date(Sys.Date()-19, Sys.Date(), by=&quot;day&quot;), indicator = c(rep(1,10),rep(2,10)), value = rnorm(20) ) left(df$value, 3) right(df$Date, 3) Bloomberg API in R Blmrg API with package Rblpapi library(Rblpapi) con &lt;- blpConnect() #generic us10 &lt;- bdh(securities = &quot;USGG10YR Index&quot;, fields = &quot;PX_LAST&quot;, start.date = as.Date(&quot;2020-03-01&quot;)) #Isin us10 &lt;- bdh(securities = &quot;US912828ZQ64 Govt&quot;, fields = &quot;PX_LAST&quot;, start.date = as.Date(&quot;2020-03-01&quot;)) ##Multiple fields bonds &lt;- c(&quot;CA135087K601 Govt&quot;,&quot;CA563469UP83 Govt&quot;) fields &lt;- c(&quot;PX_LAST&quot;, &quot;YLD_YTM_MID&quot;, &quot;PX_DIRTY_MID&quot;, &quot;Issuer&quot;, &quot;SHORT_NAME&quot;, &quot;YRS_TO_MTY_ISSUE&quot;,&quot;YAS_ASW_SPREAD&quot;, &quot;CPN&quot;, &quot;AMT_OUTSTANDING&quot;, &quot;%_OF_TSY_HLD_IN_THE_FED_RES_SOMA&quot;, &quot;YLD_CHG_NET_1D&quot;, &quot;YLD_CHG_NET_1M&quot;, &quot;INTERVAL_Z_SCORE&quot;, &quot;MTY_YEARS_TDY&quot;, &quot;YLD_CHG_NET_5D&quot;) df &lt;- bdp(securities = bonds, fields = fields) df &lt;- tibble::rownames_to_column(df, &quot;isin_govt&quot;) 1.7 R Markdown 1.7.1 Render multiple reports Render multiple reports in different folders. In the example below one report is created for each stated currency. Params = list(currency) is the key. #Write in one R Script #Remove old file.remove(&quot;...xxx/report/Benchmark_R/Portfolio_report_GBP.html&quot;) file.remove(&quot;...xxx/report/Benchmark_R/Portfolio_report_AUD.html&quot;) file.remove(&quot;...xxx/report/Benchmark_R/Portfolio_report_EUR.html&quot;) purrr::map( c(&quot;AUD&quot;, &quot;EUR&quot;, &quot;GBP&quot;), ~ { res &lt;- rmarkdown::render(&quot;...xxx\\\\report\\\\Benchmark_R\\\\R code\\\\Markdown BM.Rmd&quot;, output_file = sprintf(&quot;...xxx\\\\report\\\\Benchmark_R\\\\Portfolio_report_%s.html&quot;, .x), params = list(currency = .x)) file.copy(res, sprintf(&quot;...xxx\\\\report\\\\Benchmark_R\\\\Old_reports\\\\Portfolio_report_%1$s_%2$s.html&quot;, .x, Sys.Date())) file.copy(res, sprintf(&quot;...xxx/report/Benchmark_R//Portfolio_report_%s.html&quot;, .x)) } ) #Markdown Report header --- #title: &quot;Portfolio and benchmark report&quot; output: html_document date: &quot;`r Sys.Date()`&quot; author: christoffer.nordenlow@outlook.com params: currency: &quot;EUR&quot; title: &quot;`r sprintf(&#39;Portfolio and benchmark report, %s&#39;, params$currency)`&quot; --- 1.8 Web Scraping 1.8.1 Scrape all sub page Scrape web page info and save in a table Scrape all different sub web pages under a base page. In the below example there a number of sub pages under the base bage. R is scraping all different URL under the main page. Info in the tables under the sub pages are saved in a table. You will need to have HTTP_PROXY/HTTPS_PROXY as environment variables. #https://cran.r-project.org/web/packages/rvest/rvest.pdf require(rvest) require(xml2) require(tidyverse) .base_url &lt;- &quot;https://www.riksbank.se&quot; doc &lt;- read_html(file.path(.base_url, &quot;sv/penningpolitik/penningpolitiska-instrument/kop-av-foretagscertifikat/special-terms-and-conditions/&quot;)) urls &lt;- doc %&gt;% html_nodes(&quot;a&quot;) %&gt;% html_attr(&quot;href&quot;) urls &lt;- urls[str_detect(urls, regex(&quot;.*/special-terms-and-conditions/.*bid-date.*$&quot;))] urls &lt;- file.path(.base_url, urls) names(urls) &lt;- basename(urls) doc_subpage &lt;- read_html(urls[[1]]) df &lt;- urls %&gt;% map_dfr(~{ doc_subpage %&gt;% html_node(&quot;table&quot;) %&gt;% html_table() %&gt;% rename(key=X1, value=X2) %&gt;% as_tibble() }, .id = &quot;url&quot;) #It is possible to filter which files should be imported. #map(...) %&gt;% filter(lubridate::year(date) == 2019) 1.8.2 Scrape PL table Scrape one table library(rvest) web_pl &lt;- read_html(&quot;https://www.foxsports.com/soccer/stats?competition=1&amp;season=20190&amp;category=standard&amp;sort=3&quot;) tbls &lt;- html_nodes(web_pl, &quot;table&quot;) head(tbls) pl_stats &lt;- web_pl %&gt;% html_nodes(&quot;table&quot;) %&gt;% # .[3:4] %&gt;% html_table(fill = TRUE)%&gt;% .[[1]] 1.8.3 Scrape all tables Scrape all tables, use one ##Web scrape US Data. Payroll #http://bradleyboehmke.github.io/2015/12/scraping-html-tables.html library(rvest) web_bls &lt;- read_html(&quot;http://www.bls.gov/web/empsit/cesbmart.htm&quot;) tbls &lt;- html_nodes(web_bls, &quot;table&quot;) #extract all table nodes that exist on the page. head(tbls) #To parse the HTML, we use html_table. In this example it creates table_bls &lt;- web_bls %&gt;% html_nodes(&quot;table&quot;) %&gt;% .[3:4] %&gt;% ##determines which tables. In this case, table 3 and 4. html_table(fill = TRUE) str(table_bls) #Extract table 2, non-farm head(table_bls[[2]], 4) # remove row 1 that includes part of the headings. Not neccessary here #table_bls[[2]] &lt;- table_bls[[2]][-1,] table_bls2 &lt;-table_bls[[2]] 1.8.4 Scrape title Scrape title library(rvest) lego_movie &lt;- read_html(&quot;http://www.imdb.com/title/tt1490017/&quot;) lego_movie %&gt;% html_node(xpath=&#39;//div[@class=&quot;originalTitle&quot;]&#39;) %&gt;% html_text() "],
["excel-vba.html", "2 Excel &amp; VBA 2.1 Import 2.2 Loops 2.3 Misc 2.4 Useful excel formulas 2.5 Useful Bloomberg formulas", " 2 Excel &amp; VBA 2.1 Import 2.1.1 Standard way to import file Sub import_file() &#39;Code to delete old data and to import new file Application.ScreenUpdating = False Application.DisplayAlerts = False Sheets(&quot;location_file&quot;).ClearContents TheHomeFile = ActiveWorkbook.Name Path = &quot;\\\\riksbank.se\\profile\\home\\chnord\\My Documents\\test\\&quot; Name = &quot;likvprog_history.txt&quot; Workbooks.OpenText Filename:= _ Path &amp; Name, Local:=True Range(&quot;a1:z10000&quot;).Copy Workbooks(TheHomeFile).Activate Sheets(&quot;likvprog_history&quot;).Select Range(&quot;a1&quot;).PasteSpecial xlValues Workbooks(Name).Close savechanges:=False Sheets(&quot;main&quot;).Select Application.CutCopyMode = False End Sub 2.1.2 Import file with conditions Import files after a certain date. Check if file exists before import. Sub import_file() Application.ScreenUpdating = False Application.DisplayAlerts = False Sheets(&quot;location_file&quot;).ClearContents #Input files after this date from_date = &quot;2020-05-01&quot; current_date = from_date TheHomeFile = ActiveWorkbook.Name Path = &quot;xxx\\home\\chnord\\My Documents\\test\\&quot; Do Until Format(current_date, &quot;YYYY-MM-DD&quot;) &gt;= Format(to_date, &quot;YYYY-MM-DD&quot;) Name = current_date &amp; &quot; Saldo.csv&quot; &#39;&#39;check if file exists file_exists = False If Dir(Path &amp; Name) &lt;&gt; &quot;&quot; Then file_exists = True If file_exists = True Then Workbooks.OpenText Filename:= _ Path &amp; Name, Local:=True Range(&quot;a1:z10000&quot;).Copy Workbooks(TheHomeFile).Activate Sheets(&quot;likvprog_history&quot;).Select Range(&quot;a1&quot;).PasteSpecial xlValues Workbooks(Name).Close savechanges:=False end if current_date = DateAdd(&quot;d&quot;, 1, current_date) Loop Application.CutCopyMode = False End Sub 2.2 Loops 2.2.1 For loop Loop thru all possible scenarios. Loop All alternatives. In Rows 2:4 there are three alternatives in each column. Loop all possible scenarios. sub for_loop_all_alternatives Sheets(&quot;sheet1&quot;).Select Sheets(&quot;sheet1&quot;).Range(&quot;c2:k2&quot;) = 1 Sheets(&quot;sheet1&quot;).Range(&quot;c3:k4&quot;) = 2 Sheets(&quot;sheet1&quot;).Range(&quot;c4:k4&quot;) = 3 Count = 1 Row = 7 For c = 2 To 4 For d = 2 To 4 For e = 2 To 4 For f = 2 To 4 For g = 2 To 4 For h = 2 To 4 For i = 2 To 4 For j = 2 To 4 For k = 2 To 4 Cells(Row, 2) = Count Cells(Row, 3) = Range(&quot;c&quot; &amp; c) Cells(Row, 4) = Range(&quot;d&quot; &amp; d) Cells(Row, 5) = Range(&quot;e&quot; &amp; e) Cells(Row, 6) = Range(&quot;f&quot; &amp; f) Cells(Row, 7) = Range(&quot;g&quot; &amp; g) Cells(Row, 8) = Range(&quot;h&quot; &amp; h) Cells(Row, 9) = Range(&quot;i&quot; &amp; i) Cells(Row, 10) = Range(&quot;j&quot; &amp; j) Cells(Row, 11) = Range(&quot;k&quot; &amp; k) Count = Count + 1 Row = Row + 1 Next Next Next Next Next Next Next Next Next End Sub 2.3 Misc 2.3.1 Misc Format from text to number Format from text to number when excel “requires” a press of enter button. or Each r In Sheets(&quot;Sheet1&quot;).UsedRange.SpecialCells(xlCellTypeConstants) If IsNumeric(r) Then r.Value = CSng(r.Value) r.NumberFormat = &quot;0.00&quot; End If Next 2.4 Useful excel formulas 2.5 Useful Bloomberg formulas Import Rating with override function &#39;Approah to import rating for specific date =BDP(&quot;SAND SS equity&quot;;&quot;RTG_SP_LT_LC_ISSUER_CREDIT&quot;;&quot;RATING_AS_OF_DATE_OVERRIDE=&quot;&amp;&quot;2020-01-01&quot;) Formula for importing data to excel &#39;Import data from Bloomberg, 2 cols. =BDH(&quot;INJCJC Index&quot;;&quot;px_last&quot;;&quot;2015-07-02&quot;;&quot;&quot;;&quot;Dir=V&quot;;&quot;Dts=S&quot;;&quot;Sort=d&quot;;&quot;Quote=C&quot;;&quot;QtTyp=Y&quot;;&quot;Days=a&quot;;&quot;Per=cd&quot;;&quot;DtFmt=D&quot;;&quot;Fill=P&quot;;&quot;UseDPDF=Y&quot;;&quot;cols=2;rows=1826&quot;) "],
["fi-fx.html", "3 FI &amp; FX 3.1 Fixed Income 3.2 Foreign Exchange", " 3 FI &amp; FX 3.1 Fixed Income 3.1.1 Bond Calculator in R 3.1.1.1 Calculate Forward Rates Calculate Forward Rates Create a table with bond (or import real ones) and calculate forward rates. library(dplyr) #Calculate Forward rate #Create a table with plain vanilla bonds df &lt;- tribble( ~bond, ~maturity, ~yield, 1, 1.5, 1.65, 2, 3, 1.55, 3, 5, 1.8, 4, 10, 1.9 ) #Create table with all bonds in columns for short vs long bond df &lt;- df %&gt;% mutate(dummy = 1L) %&gt;% inner_join(., ., by = &quot;dummy&quot;, suffix=c(&quot;_short&quot;, &quot;_long&quot;)) %&gt;% select(-dummy) %&gt;% filter(bond_short &lt; bond_long) #Create column with maturity for length between bonds (not neccesary for below calculation) df &lt;- mutate(df, maturity_between_bonds = (maturity_long - maturity_short)) day_count &lt;- 360 #Create function for calculating frw rate calculate_forward_rate &lt;- function(maturity_short, yield_short, maturity_long, yield_long, day_count){ short_bond &lt;- (1+yield_short/100)^(maturity_short/day_count) long_bond &lt;- (1+yield_long/100)^(maturity_long/day_count) days_between &lt;- (maturity_long - maturity_short) forward_rate &lt;- ((long_bond/short_bond)^(360/days_between)-1)*100 return(round(forward_rate, digits=2)) } #run function df &lt;- df %&gt;% mutate(forward_rate = calculate_forward_rate( maturity_short, yield_short, maturity_long, yield_long, day_count)) #Create a yield_diff. How much more/less the yield must be when its time to buy the subsequent bond df &lt;- df %&gt;% mutate(yield_diff = if_else(bond_short == bond_long, NA_real_, forward_rate - yield_short)) 3.1.1.2 Bond Converter Calculate Bond Price Maturity &lt;- &quot;2023-04-30&quot; Handle &lt;- 100 x32 &lt;- 25 x64 &lt;- 24 cpn &lt;- 2.25 ttm &lt;- as.numeric(as.Date(Maturity) - as.Date(Sys.Date())) / 365 FV &lt;- 100 calculate_price &lt;- function(Handle, x32, x64){ bond_price &lt;- Handle + ((x32+(x64/64))/32) return(format(round(bond_price,10), nsmall=10)) } bond_price &lt;- as.numeric(calculate_price(Handle, x32, x64)) Convert from Discount to Yield discount &lt;- 1.69 maturity_date &lt;- as.Date(&quot;2021-05-06&quot;) settlement_date &lt;- Sys.Date() +1 day_count &lt;- 360 calculate_ytm_from_discount &lt;- function(discount, maturity_date, settlement_date, day_count){ days &lt;- as.numeric(maturity_date-settlement_date) discount &lt;- discount / 100 yield_ &lt;- (discount / (1-(discount * (days/day_count)))) return(format(round(yield_*100,10),nsmall=10)) } calculate_ytm_from_discount(discount, maturity_date, settlement_date, day_count) Convert from Yield to Discount yield &lt;- 1.719967 maturity_date &lt;- as.Date(&quot;2021-05-06&quot;) settlement_date &lt;- Sys.Date()+1 day_count &lt;- 360 yield &lt;- yield / 100 calculate_disc_from_yield &lt;- function(yield, maturity_date, settlement_date, day_count){ days &lt;- as.numeric(maturity_date-settlement_date) discount &lt;- (yield / (1+(yield /(day_count/days)))) return(format(round(discount*100,10),nsmall=10)) } calculate_disc_from_yield(yield, maturity_date, settlement_date, day_count) 3.2 Foreign Exchange "],
["sql.html", "4 SQL 4.1 General 4.2 SQL databases and R", " 4 SQL 4.1 General https://www.w3schools.com/sql/default.asp ‘Getting started with SQL’ using SQLite. https://github.com/thomasnield/oreilly_getting_started_with_sql ### Basic commands 4.1.0.1 SELECT SELECT * FROM CUSTOMER; SELECT CUSTOMER_ID, NAME FROM CUSTOMER; # Generate a calculated column SELECT PRODUCT_ID, DESCRIPTION, PRICE AS UNTAXED_PRICE, round(PRICE * 1.07,2) AS TAXED_PRICE FROM PRODUCT; # Text concatenation. Concatenation works with any data type. SELECT NAME, CITY || &#39;, &#39; || STATE AS LOCATION FROM CUSTOMER; 4.1.0.2 WHERE SELECT * FROM STATION_DATA WHERE year = 2010; #Use != or &lt;&gt; to get everything but 2010 SELECT * FROM STATION_DATA WHERE year != 2010; #AND, OR, IN statements SELECT * FROM STATION_DATA WHERE year &gt;= 2005 AND year &lt;= 2010; #in SELECT * FROM STATION_DATA WHERE MONTH IN (3,6,9,12) #not in SELECT * FROM STATION_DATA WHERE MONTH NOT IN (3,6,9,12) #modulus operator #modulus returns the remainder instead of the quotient. A remainder of 0 means there is no remainder at all SELECT * FROM STATION_DATA WHERE MONTH % 3 = 0 #using where on text SELECT * FROM STATION_DATA WHERE report_code in (&#39;513A63&#39;, &#39;1F8A7B&#39;) SELECT * FROM STATION_DATA WHERE length(report_code) = 6 #wildcards SELECT * FROM STATION_DATA WHERE report_code LIKE &#39;A%&#39; #B as the first, C as the third letter SELECT * FROM STATION_DATA WHERE report_code LIKE &#39;B_C%&#39; #Other text functions as INSTR, SUBSTR, REPLACE ETC SELECT * FROM station_data WHERE snow_depth IS NULL; #Use coalesce to conert NULL to 0, &quot;N/A&quot; etc SELECT * FROM station_data WHERE coalesce(precipitation,0) &lt;= 0.5; SELECT * FROM station_data WHERE (rain = 1 AND temperature &lt;= 32) OR snow_depth &gt; 0; 4.1.0.3 GROUP BY WHERE filters individual records while HAVING filters aggregations. SELECT year, month, COUNT(*) AS record_count FROM station_data WHERE tornado = 1 GROUP BY year, month ORDER BY year, month #aggregate SELECT month, AVG(temperature) as avg_temp FROM station_data WHERE year &gt;= 2000 GROUP BY month #HAVING statement #To be able to filter on aggregate data you need to use HAVING instead of WHERE SELECT year, SUM(precipitation) as total_precipitation FROM station_data GROUP BY year HAVING sum(precipitation) &gt; 30 4.1.0.4 CASE statements CASE statements are read from top to bottom, so the first true condition is the one it uses. A great benefit of CASE statements compared to WHERE is that you can apply different filters for different aggregate values. SELECT report_code, year, month, day, wind_speed, CASE WHEN wind_speed &gt;= 40 THEN &#39;HIGH&#39; WHEN wind_speed &gt;= 30 THEN &#39;MODERATE&#39; ELSE &#39;LOW&#39; END as wind_severity FROM station_data # Use of CASE to apply different filters SELECT year, month, SUM(CASE WHEN tornado = 1 THEN precipitation ELSE 0 END) as tornado_precipitation, SUM(CASE WHEN tornado = 0 THEN precipitation ELSE 0 END) as non_tornado_precipitation FROM station_data GROUP BY year, month # Use of boolean expression SELECT month, AVG(CASE WHEN rain OR hail THEN temperature ELSE null END) AS avg_precipitation_temp, AVG(CASE WHEN NOT (rain OR hail) THEN temperature ELSE null END) AS avg_non_precipitation_temp FROM station_data WHERE year &gt; 2000 GROUP BY month 4.1.0.5 JOIN In multiple joins, it may be erroundous to mix LEFT JOIN with INNER JOIN. This is becasue null values cannot be inner joined on and will get filtered out. LEFT JOIN tolerates null values. #INNER JOIN SELECT ORDER_ID, CUSTOMER.CUSTOMER_ID, ORDER_DATE, ORDER_QTY FROM CUSTOMER INNER JOIN CUSTOMER_ORDER ON CUSTOMER.CUSTOMER_ID = CUSTOMER_ORDER.CUSTOMER_ID #LEFT JOIN SELECT ORDER_ID, CUSTOMER.CUSTOMER_ID, ORDER_DATE, ORDER_QTY FROM CUSTOMER LEFT JOIN CUSTOMER_ORDER ON CUSTOMER.CUSTOMER_ID = CUSTOMER_ORDER.CUSTOMER_ID #Checking for NULL values SELECT CUSTOMER.CUSTOMER_ID, NAME AS CUSTOMER_NAME FROM CUSTOMER LEFT JOIN CUSTOMER_ORDER ON CUSTOMER.CUSTOMER_ID = CUSTOMER_ORDER.CUSTOMER_ID WHERE ORDER_ID IS NULL #Multiple joins SELECT ORDER_ID, CUSTOMER.CUSTOMER_ID, &#39;NAME AS CUSTOMER.NAME,&#39; STREET_ADDRESS, CITY, STATE, ZIP, ORDER_DATE, PRODUCT_ID, DESCRIPTION, ORDER_QTY FROM CUSTOMER INNER JOIN CUSTOMER_ORDER ON CUSTOMER_ORDER.CUSTOMER_ID = CUSTOMER.CUSTOMER_ID INNER JOIN PRODUCT ON CUSTOMER_ORDER.PRODUCT_ID = PRODUCT.PRODUCT_ID #Use coalesce() to turn nulls into zeros. SELECT CUSTOMER.CUSTOMER_ID, NAME AS CUSTOMER_NAME, coalesce(sum(ORDER_QTY * PRICE), 0) as TOTAL_REVENUE FROM CUSTOMER LEFT JOIN CUSTOMER_ORDER ON CUSTOMER.CUSTOMER_ID = CUSTOMER_ORDER.CUSTOMER_ID LEFT JOIN PRODUCT ON CUSTOMER_ORDER.PRODUCT_ID = PRODUCT.PRODUCT_ID GROUP BY 1,2 4.2 SQL databases and R 4.2.1 Accessing a database from R Access a database from R. The problem with dplyr is that all operations are conducted in-memory and thus the amount of data you can work with is limited by available memory. The database connection essentially removes that limitation. 4.2.1.1 Connecting to a database Accessing a temp database by downloading it. Dplyr and dbplyr are used in R to point to the database. #https://datacarpentry.org/R-ecology-lesson/05-r-and-databases.html library(&quot;RSQLite&quot;) library(&quot;plyr&quot;) library(&quot;dbplyr&quot;) # Downloading database for test dir.create(&quot;data_raw&quot;, showWarnings = FALSE) download.file(url = &quot;https://ndownloader.figshare.com/files/2292171&quot;, destfile = &quot;data_raw/portal_mammals.sqlite&quot;, mode = &quot;wb&quot;) # Connect to databse mammals &lt;- DBI::dbConnect(RSQLite::SQLite(), &quot;data_raw/portal_mammals.sqlite&quot;) # Querying with SQL-syntax vs dplyr syntax #sql tbl(mammals, sql(&quot;SELECT year, species_id, plot_id FROM surveys&quot;)) #dplyr surveys &lt;- tbl(mammals, &quot;surveys&quot;) surveys %&gt;% select(year, species_id, plot_id) #Checking head(surveys, n = 10) and nrow(surveys) we see that the surveys at first glance looks like a data frame but there are some differences.* head(surveys, n = 10) nrow(surveys) #The reason for this is that dplyr dosen´t see the full dataset, only what was asked for when the question in dplyr was translated into SQL. 4.2.2 Running SQL syntax in R library(sqldf) #https://dept.stat.lsa.umich.edu/~jerrick/courses/stat701/notes/sql.html#introduction sqldf(&#39;SELECT age, circumference FROM Orange WHERE Tree = 1 ORDER BY circumference ASC&#39;) sqldf(&quot;SELECT * FROM iris&quot;) #example data(BOD) BOD #Wildcard: used to extract everything bod2 &lt;- sqldf(&#39;SELECT * FROM BOD&#39;) bod2 #LIMIT controls the number of results sqldf(&#39;SELECT * FROM iris LIMIT 5&#39;) #ORDER BY syntax: ORDER BY var1 {ASC/DESC}, var2 {ASC/DESC} sqldf(&quot;SELECT * FROM Orange ORDER BY age ASC, circumference DESC LIMIT 5&quot;) #Where can be used to add conditional statements sqldf(&#39;SELECT demand FROM BOD WHERE Time &lt; 3&#39;) #WHERE with AND and OR sqldf(&#39;SELECT * FROM rock WHERE (peri &gt; 5000 AND shape &lt; .05) OR perm &gt; 1000&#39;) #IN is used to similiar to %in% sqldf(&#39;SELECT * FROM BOD WHERE Time IN (1,7)&#39;) sqldf(&#39;SELECT * FROM BOD WHERE Time NOT IN (1,7)&#39;) #LIKE weak expression command sqldf(&#39;SELECT * FROM chickwts WHERE feed LIKE &quot;%bean&quot; LIMIT 5&#39;) sqldf(&#39;SELECT * FROM chickwts WHERE feed NOT LIKE &quot;%bean&quot; LIMIT 5&#39;) #Aggregated data: AVG, MEDIAN, MAX, MIN, SUM sqldf(&quot;SELECT AVG(circumference) FROM Orange&quot;) #SELECT COUNT d &lt;- data.frame(a = c(1,1,1), b = c(1,NA,NA)) d sqldf(&quot;SELECT COUNT() as numrows FROM d&quot;) sqldf(&quot;SELECT COUNT(b) FROM d&quot;) "]
]
