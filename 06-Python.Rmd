
# Python

## Basic

## Scrapy

*pip install Scrapy*

### Shell commands

*Run scrapy in shell: Write 'scrapy shell' in miniconda*

*Fetch page: Write 'Fetch ("https://www.riksbank.se/sv/penningpolitik/penningpolitiska-instrument/kop-av-foretagscertifikat/auction-results/2020/results-of-auctions-2020-09-23/")'*

*Use view(response)*


### Scrape table

```{python}
# Spider

import scrapy


class ToScrapeCSSSpider(scrapy.Spider):
    name = "rb_scrape2"
    start_urls = [

        'https://www.riksbank.se/sv/penningpolitik/penningpolitiska-instrument/kop-av-foretagscertifikat/auction-results/2020/results-of-auctions-2020-09-23/'
    ]

    def parse(self, response):


        for item in response.xpath('//*[@class="page-base__main__body"]//tr'):
            yield {

            'terms' : item.xpath('td[1]//text()').extract(),
            'auction' : item.xpath('td[2]//text()').extract()

            }

        next_page_url = response.css("li.next > a::attr(href)").extract_first()
        if next_page_url is not None:
            yield scrapy.Request(response.urljoin(next_page_url))


# Settings

#Export as CSV Feed
#FEED_FORMAT = "csv"
#FEED_URI = "rbbot.csv"

#Run crawler in miniconda with creating an csv (if its not in settings): scrapy crawl rb_scrape2 -o quotes.csv

```
